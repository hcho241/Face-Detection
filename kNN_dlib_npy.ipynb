{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Import necessary libraries =====\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import dlib\n",
    "import glob\n",
    "import face_recognition\n",
    "from skimage import io\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Initialize varialbes =====\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "face_recognition_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "count = 1\n",
    "dataset_path = './knn_dlib/'\n",
    "offset = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) ========== capture image ==========\n",
    "webcam = cv2.VideoCapture(0)\n",
    "# ===== Ask user to enter name to create his/her image folder =====\n",
    "file_name = input(\"Enter the name of the person :  \")\n",
    "# ===== capture 30 → 20 images =====\n",
    "while (webcam.isOpened() and count <= 10) :\n",
    "    ret,frame = webcam.read()\n",
    "    if(ret == False):\n",
    "        continue\n",
    "    # ===== convert to gray frame =====\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "    faces = sorted(faces, key=lambda f:f[2]*f[3])    # it was used in openCV -> not sure about deleting it\n",
    "    for (x, y, w, h) in faces : #face in faces : \n",
    "        #print(face)\n",
    "        #x, y, w, h =  face \n",
    "        # ===== draw bounding box around face =====\n",
    "        #cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    # ===== extract only face in different window =====\n",
    "        face_section = frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(150, 150))\n",
    "        #print('face section', face_section)\n",
    "    # ===== create file_name folder under knn_dlib =====\n",
    "    if not os.path.exists(dataset_path + \"/\" + file_name):\n",
    "        os.makedirs(dataset_path + \"/\" + file_name)\n",
    "    # ===== save key image as frame size =====\n",
    "    #fileName = dataset_path + \"/\" + file_name + \"/\" + file_name + \"_\" + str(count) + \".jpg\"\n",
    "    #cv2.imwrite(fileName, frame)\n",
    "    # ===== save key image as face_section size =====\n",
    "    fileName = dataset_path + \"/\" + file_name + \"/\" + file_name + \"_\" + str(count) + \".jpg\"\n",
    "    cv2.imwrite(fileName, face_section)\n",
    "    # ===== increment count =====\n",
    "    count += 1\n",
    "    print('count', count)\n",
    "    # ===== Display both window =====\n",
    "    cv2.imshow(\"FACE CROP\",face_section) \n",
    "    cv2.imshow(\"CAPTURE IMG\",frame)\n",
    "    # ===== Hit 'q' to QUIT =====\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "# ===== Reset count to 1 & close webcam + window =====\n",
    "#count = 1\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2) load image and save its info as a key to compare ==========\n",
    "def get_face_encodings(face):\n",
    "    \"\"\"\n",
    "        return np.array of face recognition model which contains location, landmarks for face encoding\n",
    "    \"\"\"\n",
    "    bounds = face_detector(face, 1) # detect face rectangles \n",
    "    faces_landmarks = [shape_predictor(face, face_bounds) for face_bounds in bounds]\n",
    "    return [np.array(face_recognition_model.compute_face_descriptor(face, face_pose, 1)) for face_pose in faces_landmarks]\n",
    "\n",
    "def get_face_matches(known_faces, face):\n",
    "    \"\"\"\n",
    "        return euclidean distance \n",
    "    \"\"\"\n",
    "    return np.linalg.norm(known_faces - face, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(known_faces, person_name, face):\n",
    "    \"\"\"\n",
    "        min distance is the best prediction \n",
    "    \"\"\"\n",
    "    matches = get_face_matches(known_faces, face) \n",
    "    print('matches ', matches)\n",
    "    min_index = matches.argmin() # min distance index\n",
    "    print('min index ', min_index)\n",
    "    min_value = matches[min_index] # min distance\n",
    "    print('min value ', min_value)\n",
    "    matchPercent = 100 - (min_value * 100) # convert to percentage\n",
    "    print('matchPercent ', matchPercent, ' person name ', person_name)\n",
    "    if matchPercent >= 70 : # at least 80% of correction -> change to 70\n",
    "        return person_name +\" {0:.2f}%\".format(matchPercent)\n",
    "    return 'Not Found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face_encodings(faces_folder_path):\n",
    "    \"\"\"\n",
    "        Load face images in person's name folder in a separate window \n",
    "    \"\"\"\n",
    "    image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir(faces_folder_path))\n",
    "    image_filenames = sorted(image_filenames)\n",
    "    person_names = []\n",
    "    for x in image_filenames :\n",
    "        #print('image file name ', x)\n",
    "        index = x.find('_')\n",
    "        person_names.append(x[:index]) # exclude from '_'\n",
    "    full_paths_to_images = [faces_folder_path + x for x in image_filenames]\n",
    "    print('full paths to images ', full_paths_to_images)\n",
    "    face_encodings = []\n",
    "    \n",
    "    for path_to_image in full_paths_to_images:\n",
    "        face = io.imread(path_to_image)\n",
    "        faces_bounds = face_detector(face, 1)\n",
    "        if len(faces_bounds) != 1:\n",
    "            print(\"Expected one and only one face per image: \" + path_to_image + \" - it has \" + str(len(faces_bounds)))\n",
    "        face_bounds = faces_bounds[0]\n",
    "        # Get pose/landmarks of those faces\n",
    "        # Will be used as an input to the function that computes face encodings\n",
    "        # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
    "        face_landmarks = shape_predictor(face, face_bounds)\n",
    "        \n",
    "        # initialize the list of (x, y)-coordinates\n",
    "        coords = np.zeros((68, 2), dtype='int')\n",
    "        \n",
    "        # loop over the 68 facial landmarks and convert them\n",
    "        # to a 2-tuple of (x, y)-coordinates\n",
    "        for i in range(0, 68):\n",
    "            coords[i] = (face_landmarks.part(i).x, face_landmarks.part(i).y)\n",
    "        print('coords ', coords)\n",
    "        face_encoding = np.array(face_recognition_model.compute_face_descriptor(face, face_landmarks, 1))\n",
    "        face_encodings.append(face_encoding)\n",
    "    #print('face encoding result ', face_encoding)\n",
    "\n",
    "    # ===== save this data into numpy array file & text file =====\n",
    "    np.save(dataset_path + person_names[0] + '.npy', face_encoding)\n",
    "    print(\"data successfully saved at \" + dataset_path + person_names[0] + '.npy')\n",
    "    return person_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(data_dir) :\n",
    "    \"\"\"\n",
    "        Data Preparation by loading npy file \n",
    "    \"\"\"\n",
    "    face_data = []\n",
    "    for dataset in os.listdir(data_dir):\n",
    "        #print(\"Loaded \"+ dataset)\n",
    "        if dataset.endswith('.npy'):\n",
    "            data_item = np.load(dataset_path + dataset)\n",
    "            face_data.append(data_item)\n",
    "    return face_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3) initialize webcam to compare key image features ==========\n",
    "\n",
    "data_dir = os.path.expanduser('./knn_dlib')\n",
    "faces_folder_path = data_dir + '/hy/'  # just need to change folder's name to encode \n",
    "        \n",
    "# ===== use timer to get how long it takes to load face encoding =====\n",
    "start_loading = time.time()\n",
    "person_name = load_face_encodings(faces_folder_path)\n",
    "end_loading = time.time()\n",
    "total_loading = end_loading - start_loading\n",
    "print('Took {0:.2f} seconds to load face encodings'.format(total_loading))\n",
    "\n",
    "# ===== load npy file =====\n",
    "face_data = data_preparation(data_dir)\n",
    "\n",
    "# ===== initialize webcam =====\n",
    "camera = cv2.VideoCapture(0)\n",
    "old_faces = []\n",
    "cnt = 1\n",
    "similarity_threshold = 0.4\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (0, 0), fx = 0.5, fy = 0.5)    \n",
    "    faces = face_detector(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_rects = face_cascade.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5, minSize = (50, 50), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    if len(old_faces) < len(faces) :\n",
    "        old_faces = []\n",
    "        for face in faces :\n",
    "            tracker = dlib.correlation_tracker()\n",
    "            tracker.start_track(frame, face)\n",
    "            old_faces.append(tracker)\n",
    "    else :\n",
    "        for i, tracker in enumerate(old_faces) :\n",
    "            quality = tracker.update(frame)\n",
    "            if quality > 8 :\n",
    "                pos = tracker.get_position()\n",
    "                pos = dlib.rectangle(int(pos.left()), int(pos.top()), int(pos.right()), int(pos.bottom()))\n",
    "                face = frame[pos.top():pos.top() + pos.bottom(), pos.left():pos.left() + pos.right()]\n",
    "                start = time.time() \n",
    "                face_encodings_in_image = get_face_encodings(face)\n",
    "                if (face_encodings_in_image) :\n",
    "                    match = find_match(face_data, person_name, face_encodings_in_image[0])\n",
    "                    end = time.time()\n",
    "                    total = end - start\n",
    "                    print('Encoding Image Match Found took {0:.2f} seconds'.format(total))\n",
    "                    cv2.putText(frame, match, (pos.left()-50, pos.top()-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                else : \n",
    "                    pos = tracker.get_position()\n",
    "                    pos = dlib.rectangle(int(pos.left()), int(pos.top()), int(pos.right()), int(pos.bottom()))\n",
    "                    unknown_face = frame[pos.top():pos.top() + pos.bottom(), pos.left():pos.left() + pos.right()]\n",
    "                    start = time.time() \n",
    "                    known_face = face_encodings_in_image\n",
    "                    unknown_face = face_recognition.face_encodings(unknown_face)\n",
    "                    result = face_recognition.compare_faces(known_face, unknown_face)\n",
    "                    if result[0] :\n",
    "                        cv2.putText(frame, \"Unknown\", (pos.left()-15, pos.top()-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                    else :\n",
    "                        cv2.putText(frame, person_name, (pos.left()-15, pos.top()-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                cv2.rectangle(frame, (pos.left(), pos.top()), (pos.right(), pos.bottom()), (0, 255, 255), 2)\n",
    "            else:\n",
    "                old_faces.pop(i)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FROM here, load each npy files to detect multiple people at the same time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data_dir) :\n",
    "    \"\"\"\n",
    "        Data Preparation by loading each npy file \n",
    "    \"\"\"\n",
    "    face_data = []\n",
    "    person_names = []\n",
    "    #result = {}\n",
    "    for dataset in os.listdir(data_dir):\n",
    "        #print(\"Loaded \"+ dataset)\n",
    "        if dataset.endswith('.npy'):\n",
    "            print('dataset ', dataset)\n",
    "            index = dataset.index('.')\n",
    "            person_name = dataset[:index]\n",
    "            data_item = np.load(dataset_path + dataset)\n",
    "            face_data.append(data_item)\n",
    "            person_names.append(person_name)\n",
    "            #result[person_name] = data_item\n",
    "        else : \n",
    "            continue \n",
    "    return person_names, face_data #result\n",
    "\n",
    "#output = data_preparation(data_dir)\n",
    "#print('output ', output, '\\n size ', len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare unknown faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_unknown_faces(face, unknown_faces):\n",
    "    similarity_threshold = 0.4\n",
    "    # distance를 구함\n",
    "    encodings = [face.encoding for face in unknown_faces]\n",
    "    distances = face_recognition.face_distance(encodings, face.encoding)\n",
    "    index = np.argmin(distances)\n",
    "    min_value = distances[index]    # distance의 최소값을 구함\n",
    "    if min_value < similarity_threshold :\n",
    "        # two faces are similar - create new person with two faces\n",
    "        person = Person()\n",
    "        newly_known_face = unknown_faces.pop(index)\n",
    "        person.add_face(newly_known_face)\n",
    "        person.add_face(face)\n",
    "        person.calculate_average_encoding()   # 얼굴의 face_encoding의 평균\n",
    "        return person\n",
    "    else:\n",
    "        # unknown face\n",
    "        unknown_faces.append(face)\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
